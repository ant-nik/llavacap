{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO88cI6kLyArdzAcr6BCRhN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Foundation models for zero-shot detection and segmentation\n",
        "\n",
        "Based on [Ollama](https://github.com/ollama/ollama) project."
      ],
      "metadata": {
        "id": "hc5E2kAe2Gxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T9lBpOTx6Vx"
      },
      "outputs": [],
      "source": [
        "!curl -L https://ollama.com/download/ollama-linux-amd64 -o ollama\n",
        "!chmod +x ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.Popen([\"./ollama\", \"serve\"])\n",
        "import time\n",
        "time.sleep(3)"
      ],
      "metadata": {
        "id": "HEwUusm_zUO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./ollama pull llava"
      ],
      "metadata": {
        "id": "go9ITRfcWHeR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O image.jpg https://github.com/ant-nik/neural_network_course/blob/main/practice_2_data/video_1_fixed/image_001.jpg?raw=true"
      ],
      "metadata": {
        "id": "jzFdqEqE7IUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prompt.txt\n",
        "Describe entities on the image as detailed as possible."
      ],
      "metadata": {
        "id": "0wpuEkm6Kw9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo '{ \"model\": \"llava\", \"prompt\": \"'`cat prompt.txt`'\", \"images\": [\"'`base64 -w 0 /content/image.jpg`'\"], \"stream\": false}' > llava-request.json\n",
        "!cat llava-request.json"
      ],
      "metadata": {
        "id": "MijjTNOaBUcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o llava-reply.json http://localhost:11434/api/generate --data-binary \"@llava-request.json\"\n",
        "!cat llava-reply.json"
      ],
      "metadata": {
        "id": "3CI_pQpD1hnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile llama-prompt-prefix.txt\n",
        "Extract all nouns from the TEXT section that are physical objects or living beings.\n",
        "Split answer in two parts: OUTPUT and INFO.\n",
        "In OUTPUT section place extracted nouns without enumerations symbols and one entity per line.\n",
        "Put detailed explanation of the answer to INFO section.\n",
        "\n",
        "TEXT:"
      ],
      "metadata": {
        "id": "oymKK-HjQxLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"llama-prompt-prefix.txt\") as prompt_file:\n",
        "    llama_prompt = prompt_file.read()\n",
        "with open(\"llava-reply.json\", \"r\") as llava_file:\n",
        "    llava_answer = json.loads(llava_file.read())[\"response\"].replace('\"', '\\\\\"')\n",
        "    llama_prompt += llava_answer\n",
        "llama_prompt += \"\\n\\nOUTPUT:\\n\\n\"\n",
        "with open(\"llama-prompt.txt\", \"w\") as llama_prompt_file:\n",
        "    llama_prompt_file.write(llama_prompt)"
      ],
      "metadata": {
        "id": "N0aySXk6ZtY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat llama-prompt.txt"
      ],
      "metadata": {
        "id": "A9CWZ5sadfgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo '{ \"model\": \"llama3.1\", \"prompt\": \"'`cat llama-prompt.txt`'\", \"stream\": false}' > llama_request_body.json\n",
        "!cat llama_request_body.json"
      ],
      "metadata": {
        "id": "_Z_gdkksVnfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./ollama pull llama3.1"
      ],
      "metadata": {
        "id": "4-jPNPWhf9vK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --data-binary \"@llama_request_body.json\" -o llama_reply.json http://localhost:11434/api/generate\n",
        "!cat llama_reply.json"
      ],
      "metadata": {
        "id": "wLjmLIhW7xHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def load_answer(filename: str) -> dict[str, any]:\n",
        "    with open(filename, \"r\") as file:\n",
        "        step2_response = json.loads(file.read())\n",
        "    return step2_response[\"response\"] if \"response\" in step2_response else step2_response"
      ],
      "metadata": {
        "id": "9nTA2MFGZ1V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step2_response = load_answer(\"llama_reply.json\")\n",
        "print(step2_response)"
      ],
      "metadata": {
        "id": "TjcieI3VILcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = [item for item in step2_response.replace(\"*\",\"\").replace(\":\", \"\").split(\"OUTPUT\")[1].split(\"INFO\")[0].split(\"\\n\") if not item=='']\n",
        "objects"
      ],
      "metadata": {
        "id": "XKHsQG7gfjA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
        "\n",
        "model_id = \"IDEA-Research/grounding-dino-base\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id).to(device)\n",
        "\n",
        "image = Image.open(\"image.jpg\")"
      ],
      "metadata": {
        "id": "3-X2PYNUgZaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VERY important: text queries need to be lowercased + end with a dot\n",
        "text = \" . \".join([f\"all {item}\" for item in objects]).lower() + '.'\n",
        "print(text)"
      ],
      "metadata": {
        "id": "xsTCl5eLsWtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VERY important: text queries need to be lowercased + end with a dot\n",
        "text = \" . \".join([f\"{item}\" for item in objects]).lower() + '.'\n",
        "print(text)"
      ],
      "metadata": {
        "id": "3ZT4UFQIkBNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "results = processor.post_process_grounded_object_detection(\n",
        "    outputs,\n",
        "    inputs.input_ids,\n",
        "    box_threshold=0.17,\n",
        "    text_threshold=0.17,\n",
        "    target_sizes=[image.size[::-1]]\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "id": "qUGbiQKPtEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "SDwmJcs2BIat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "id": "vZQKC1XbhwQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = results[0][\"labels\"]\n",
        "unique_classes = list(set(labels))\n",
        "class_to_index_map = {\n",
        "    item: unique_classes.index(item) for item in unique_classes\n",
        "}\n",
        "classes = [class_to_index_map[item] for item in results[0][\"labels\"]]\n",
        "unique_classes"
      ],
      "metadata": {
        "id": "4eyGAmbfoA9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision\n",
        "import numpy\n",
        "\n",
        "\n",
        "box_annotator = supervision.BoxAnnotator()\n",
        "label_annotator = supervision.LabelAnnotator()\n",
        "\n",
        "image_boxes = supervision.Detections(\n",
        "    xyxy=results[0][\"boxes\"].cpu().numpy(),\n",
        "    class_id=numpy.array(classes, dtype=int)\n",
        ")\n",
        "\n",
        "#, 2, 3, 4])#results[0][\"labels\"]\n",
        "\"\"\"\n",
        "labels = [\n",
        "    f\"{class_id} {confidence:0.2f}\"\n",
        "    for confidence, class_id, boxes in results\n",
        "]\n",
        "\"\"\"\n",
        "annotated_frame = box_annotator.annotate(scene=image.copy(),\n",
        "                                         detections=image_boxes) #, labels=labels)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=image_boxes,\n",
        "    labels=labels\n",
        ")\n"
      ],
      "metadata": {
        "id": "Fg-kM7s_iTjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "supervision.plot_image(annotated_frame, (16, 16))"
      ],
      "metadata": {
        "id": "SkMo2CRt3OU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objects count by confidence score thresholds"
      ],
      "metadata": {
        "id": "ck1zy9IUD4xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    all_outputs = model(**inputs)\n",
        "\n",
        "all_results = processor.post_process_grounded_object_detection(\n",
        "    outputs,\n",
        "    inputs.input_ids,\n",
        "    box_threshold=0.17,\n",
        "    text_threshold=0.17,\n",
        "    target_sizes=[image.size[::-1]]\n",
        ")"
      ],
      "metadata": {
        "id": "mzEUUbhWD34b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results"
      ],
      "metadata": {
        "id": "alwjAW9gHQF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = numpy.linspace(0.01, 1, 100)\n",
        "y = numpy.diff([len([x for x in filter(lambda x: x > threshold, all_results[0][\"scores\"])]) for threshold in x])"
      ],
      "metadata": {
        "id": "sdVhFixeEOKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express\n",
        "\n",
        "\n",
        "plotly.express.line(x=x[1:], y=y)"
      ],
      "metadata": {
        "id": "2RGWL-5yjUPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotly.express.histogram(y)"
      ],
      "metadata": {
        "id": "6TsKdy2OjYAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy.quantile(y, [0.01, 0.05, 0.1, 0.15, 0.2])"
      ],
      "metadata": {
        "id": "wx0W0PIWoB0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5/99"
      ],
      "metadata": {
        "id": "_aRC3ybZomYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ct8tlPMrm2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}